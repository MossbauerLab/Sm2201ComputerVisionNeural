# -*- coding: utf-8 -*-
"""power.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fKP_eb2bZi9S4blqgnoBrPEfMSiyjf6A
"""

from tensorflow.python.keras.preprocessing.image import ImageDataGenerator
from tensorflow.python.keras.models import Sequential, Model
from tensorflow.python.keras.layers import Conv2D, MaxPooling2D
from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense

from tensorflow.python.keras.models import load_model

train_dir = '/content/drive/My Drive/pressure_gauge/шкаф/train'

# Каталог с данными для проверки
val_dir = '/content/drive/My Drive/pressure_gauge/шкаф/val'
# Размеры изображения
img_width, img_height = 300, 100
# Размерность тензора на основе изображения для входных данных в нейронную сеть
# backend Tensorflow, channels_last
input_shape = (img_width, img_height, 3)
# Количество эпох
epochs = 10
# Размер мини-выборки
batch_size = 10
# Количество изображений для обучения
nb_train_samples = 400
# Количество изображений для проверки
nb_validation_samples = 5
# Количество изображений для тестирования
nb_test_samples = 1

model = Sequential()
model.add(Conv2D(64, (3, 3), padding='same',input_shape=input_shape, activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.50))
model.add(Flatten())
model.add(Dense(4))
model.add(Activation('softmax'))
model.summary()

from keras import optimizers
sgd = optimizers.SGD(lr=0.001, clipvalue=0.5)

model.compile(loss='categorical_crossentropy',
              optimizer='SGD',
              metrics=['accuracy'])
from google.colab import drive
drive.mount('/content/drive')

datagen = ImageDataGenerator(rescale=1. / 255)
train_generator = datagen.flow_from_directory(
    train_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')
val_generator = datagen.flow_from_directory(
    val_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='categorical')

model.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_samples // batch_size,
    epochs=epochs)

scores=model.evaluate(val_generator)
print(scores)

print(model.shape)

model = load_model('/content/drive/My Drive/pressure_gauge/шкаф/power.h5')
model.load_weights('/content/drive/My Drive/pressure_gauge/шкаф/power_weights.h5')

model.save('/content/drive/My Drive/pressure_gauge/шкаф/power.h5')

model.save_weights('/content/drive/My Drive/pressure_gauge/шкаф/power_weights.h5')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from keras.preprocessing import image
import matplotlib.pyplot as plt
# %matplotlib inline

model.compile(loss='categorical_crossentropy',
              optimizer='SGD',
              metrics=['accuracy'])

classes=['1','2','3','4']

img_path = '/content/drive/My Drive/pressure_gauge/шкаф/train/eror/eror.1.jpg'
img = image.load_img(img_path, target_size = (100,300))
plt.imshow(img)
plt.show()

x=image.img_to_array(img)
x/=255
x=np.expand_dims(x, axis=0)

from keras.utils import to_categorical

prediction = model.predict(x)
#prediction = to_categorical(prediction, dtype = 'int32')
#print(classes[prediction[0][0][0]])
print(prediction)
print(np.argmax(prediction))

from keras.utils import np_utils

img_path = '/content/drive/My Drive/pressure_gauge/шкаф/train/minus/minus.1.jpg'
img = image.load_img(img_path, target_size = (300,100))
plt.imshow(img)
plt.show()
x=image.img_to_array(img)
x/=255
x=np.expand_dims(x, axis=0)
#prediction = model.predict(x)
#prediction = to_categorical(prediction, dtype = 'int32')
#print(classes[prediction[0][0][0]])
#print(np.argmax(prediction))



activation_model = Model(inputs = model.input, outputs=model.layers[0].output )
activation_model.summary()

activation = activation_model.predict(x)
print(activation.shape)

plt.matshow(activation[0,:,:,1],cmap='viridis')

n_filters = activation.shape[-1]
size = activation.shape[1]
n_cols = n_filters // 16
display_grid = np.zeros((n_cols*size,16*size))

for col in range(n_cols):
  for row in range(16):
    channel_image = activation[0,:,:,col*16+row]
    channel_image-=channel_image.mean()
    channel_image/=channel_image.std()
    channel_image*=64
    channel_image+=128
    channel_image=np.clip(channel_image,0,255).astype('uint8')
    display_grid[col*300:(col+1)*300,row*100:(row+1)*100]=channel_image

scale=1./size
plt.figure(figsize=(0.01*display_grid.shape[1],0.01*display_grid.shape[0]))
plt.grid(False)
plt.imshow(display_grid, aspect='auto',cmap='viridis')

img_path = '/content/drive/My Drive/pressure_gauge/шкаф/train/overload/overload.1.jpg'
img = image.load_img(img_path, target_size = (100,300))
plt.imshow(img)
plt.show()
x=image.img_to_array(img)
x/=255
x=np.expand_dims(x, axis=0)
prediction = model.predict(x)

#prediction = to_categorical(prediction[0], 4, dtype = 'int32')
#print(classes[prediction[0][0][0]])
print(np.argmax(prediction))

img_path = '/content/drive/My Drive/pressure_gauge/шкаф/train/plus/plus.1.jpg'
img = image.load_img(img_path, target_size = (100,300))
plt.imshow(img)
plt.show()
x=image.img_to_array(img)
x/=255
x=np.expand_dims(x, axis=0)
prediction = model.predict(x)
#prediction = to_categorical(prediction, 4)
print(np.argmax(prediction))

help(model)